\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[activeacute,spanish]{babel}
\usepackage[vmargin=4cm,tmargin=3cm,hmargin=2cm,letterpaper]{geometry}%
\usepackage{helvet}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{tabls}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{url}
\usepackage{listings}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tikz}
\usepackage{pgf}
\usepackage{pgffor}
\usepgfmodule{plot}
\usepackage{wrapfig}
\lstset{language=C++}

\usetikzlibrary{arrows,decorations,snakes,backgrounds,fit,calc,through,scopes,positioning,automata,chains,er,fadings,calendar,matrix,mindmap,folding,patterns,petri,plothandlers,plotmarks,shadows,shapes,shapes.arrows,topaths,trees}

\lstset{% general command to set parameter(s)
%   basicstyle=\small,
  % print whole listing small
%   keywordstyle=\color{black}\bfseries\underbar,
  % underlined bold black keywords
%   identifierstyle=,
  % nothing happens
%   commentstyle=\color{white}, % white comments
%   stringstyle=\ttfamily,
  % typewriter type for strings
  showstringspaces=false}
  % no special string spaces

\pagestyle{fancy}
\color{black}
\fancyhead{}
\renewcommand{\headrule}{\hrule\vspace*{0.5mm}\rule{\linewidth}{0.8mm}}
\renewcommand{\familydefault}{\sfdefault}

\graphicspath{{./images/}}
\lhead{\includegraphics[width=4cm]{pictures/ucr.png}}
\rhead{\includegraphics[width=3cm]{pictures/eie.png}}
\chead{UNIVERSIDAD DE COSTA RICA\\FACULTAD DE INGENIERÍA\\ESCUELA DE INGENIERÍA ELÉCTRICA\\\textbf{ESTRUCTURAS ABSTRACTAS DE DATOS Y\\ ALGORITMOS PARA INGENIERÍA}\\IE-0217\\II CICLO 2014\\PROYECTO FINAL}

\lfoot{}%
\cfoot{}%
%\cfoot{\thepage\ de \pageref{LastPage}}%
\rfoot{}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}\vspace*{2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\Huge
\userinput{Detección de objetos en 2D mediante la cámara superior del NAO}
\vspace*{1cm}
\end{center}

\noindent
\small\baselineskip=14pt
\textbf{Estudiantes/Carné:} \userinput{\\Boris Altamirano Chinchilla - B30255 \\Carlos Eduardo Solano Abarca - B36685 \\Heberth Valverde Gardela - B37174}\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}
El presente trabajo se basó en la creación de una librería en C++ para la detección de objetos con representación bidimensional con las cámaras del robot NAO. El programa indica al NAO que gire su cabeza en busca de un objeto que se indica previamente, mediante los algoritmos SIFT y SURF se compara las imágenes captadas por la cámara del NAO y cuando lo encuentra mueve su cabeza con el fin de centrar el objeto en la escena vista por el NAO, y así posteriormente se dirige hacia el mismo.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introducción}
NAO es un robot humanoide que ha ganado mucha popularidad en los últimos años debido a sus aplicaciones educativas, el NAO H25 es el modelo más nuevo de esta gama de robots, cuenta con 25 grados de libertad, puede mover su cabeza $68^{\circ}$ en posición vertical y $239^{\circ}$ en posición vertical, lo que le permite ver mediante sus dos cámaras $61^{\circ}$ horizontalmente y $47^{\circ}$ verticalmente, además posee un sensor de inercia y cuatro micrófonos direccionales, entre otras funciones, que les permiten detectar lo que hay a su alrededor(Aldebaran Community, 2013).\\\\
Las dos cámaras del NAO pueden capturar hasta 30 imágenes por segundo, estas son procesadas por el software, y mediante la implementación de una serie de algoritmos el robot puede reconocer quién le habla o una bola roja pequeña, también mediante el programa Choregraphe se pueden guardar nuevos objetos en la memoria del NAO para que pueda reconocerlos posteriormente. Es posible crear módulos propios que interactúan con OpenCV para permitir al NAO reconocer una gama más amplia de objetos.\\\\
Como ya se mencionó, el sistema operativo de los NAO cuenta con un módulo precargado que permite el reconocimiento de objetos circulares rojos, este módulo se vale del procesamiento de video para obtener las imágenes captadas por las cámaras del NAO, luego filtra la imagen por el color de los pixeles y finalmente analiza la forma del conjunto de pixeles filtrados. Una vez que se detectada la imagen se necesario guardar varios parámetros relacionados con ella, como el tiempo en el cual se detectó, las coordenadas y el tamaño del objeto y la posición de la cámara, además de cuál de las dos fue la que detectó el objeto (Solano, 2014).\\\\
El reconocimiento facial es más complejo que la detección de objetos, ya que no consiste únicamente en detectar las características básicas de un rostro (ojos, nariz, boca, etcétera) y ubicarlas en el espacio, sino que también se debe comparar con una base de datos para identificar el rostro, por lo que se requiere mucha precisión para distinguir una característica de otra. También existen una serie de parámetros que se guardan en la memoria al momento de detectar un rostro.\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objetivos}
\subsection{Objetivo General}
Extender mediante una librería de C++ las funciones existentes de los NAOs relacionadas con los sensores visuales, como lo son las cámaras integradas.
\subsection{Objetivos Específicos}

Los objetivos específicos son:\\

\begin{enumerate}
\item Estudiar los API de reconocimiento de objetos y otros que incluyan funciones relacionadas con las cámaras de los NAOs.
\item Extender el reconocimiento de objetos de los robots NAOs utilizando las herramientas existentes.
\item Ejemplificar los logros alcanzados con un programa básico.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Justificación}
En un robot humanoide existen diversas características importantes a tener en cuenta para un funcionamiento útil y eficaz del mismo. Una de las principales características es la capacidad de reconocimiento de objetos y personas mediante las cámaras integradas del mismo. Esta característica es muy importante, ya que brinda una mayor autonomía y utilidad al robot.\\\\
Los robots NAO que se encuentran actualmente en el PRIS-Lab tienen una capacidad muy limitada en cuanto a esta característica, ya que en el caso de reconocimiento de objetos, solo cuentan con un programa para reconocer una bola de color rojo, por este motivo es de gran importancia expandir ese reconocimiento a más objetos y optimizar esta característica a fin de poder utilizar al robot para tareas complejas. Como por ejemplo recojer objetos del suelo, reconocerlos como basura y arrojarlos al basurero.\\\\
Al construir sobre el NAO, una plataforma de mayor nivel para los sensores se garantiza que la persona que lo supervisa podrá invertir menos esfuerzo y tiempo para desempeñar con el NAO las tares que desee.\\\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmos de detección de características visuales}
Según Arancil (2012) los algoritmos SIFT y SURF permiten caracterizar la información que se obtiene de una imagen para que permanezca invariante a cambios en la escala, rotación y alteraciones parciales de iluminación. Se procederá a explicar ambos algoritmos así como una comparación entre ellos.\\\\
\subsection{SIFT (Scale Invariant Features Transform)}
El autor anterior menciona que el algoritmo SIFT fue desarrollado en 1999 por David Lowe y consiste en una transformación a las características de la imagen para que pueda hallarse una correspondencia entre ella y la imagen buscada, para obtener las características de la imagen se deben llevar a cabo cuatro etapas:
\subsubsection{Detección de máximos y mínimos de espacio-escala}
En esta etapa del algoritmo se aplica la función escala-espacio $L(x,y,\sigma)$ para la búsqueda de los keypoints (puntos características) en todas las locaciones de las diferentes escalas, esta función se define como la convolución de la Gaussiana $G(x,y,\sigma)$ con la imagen $I(x,y)$. Posteriormente se utiliza la diferencia de Gaussianas convolucionada con la imagen $D(x,y,\sigma)= (G(x,y,k\sigma)-G(x,y,\sigma))*I(x,y)$ para eliminar los keypoints inestables y así hacer más rápida la búsqueda (Romero $\&$ Cazorla, 2009; Plaza $\&$ Zambrano, 2012).
\subsubsection{Localización de los keypoints}
Para detectar los máximos y mínimos locales se compara cada punto obtenido con sus ocho vecinos de la imagen actual y con sus nueve vecinos de la imagen superior e inferior, de estos puntos se debe guardar su escala, y la fila y columna donde se encuentran, ya que esto permite posteriormente identificar los keypoints para realizar la comparación (Romero $\&$ Cazorla, 2009; Plaza $\&$ Zambrano, 2012).
\subsubsection{Asignación de orientación}
Para calcular la orientación del keypoint se calcula la magnitud del gradiente como\\
\begin{center}
$ m(x,y) = \sqrt{(L(x+1,y)-L(x-1,y))^{2}+(L(x,y+1)-L(x,y-1))^{2}}$
\end{center} y su orientación mediante $\Theta = \arctan \dfrac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}$ (Romero $\&$ Cazorla, 2009). Para cada keypoitn se debe crear un histograma de 36 orientaciones donde se almacenan los valores ponderados de la magnitud del gradiente al pasar por la ventana circular gaussiana $\sigma = 1.5 \times$ escala (Plaza $\&$ Zambrano, 2012).
\subsubsection{Descripción del punto de interés}
Para describir cada keypoint se calculan los gradientes de los vecinos del punto de interés y después se rotan las coordenadas del descriptor de forma relativa a la orientación del keypoint de la tercera etapa para que permanezca invariante (Romero $\&$ Cazorla, 2009).
Al cumplir estas etapas se obtienen descriptores altamente distintivos que permiten realizar una correspondencia de características entre dos imágenes (Plaza $\&$ Zambrano, 2012).\\\\
\subsection{SURF (Speeded Up Robust Features)}
Este algoritmo utiliza muchas de las funciones de SIFT pero presenta algunas mejoras, como lo es un considerable tiempo de computación menor sin perder precisión y mayor robustez ante las variaciones en la imagen (Arancil, 2012). Fue desarrollado por Herbet Bay en el 2006, y es más rápido que el SIFT porque los keypoints poseen menos descriptores, ya que la mayoría poseen un valor de cero (Plaza $\&$ Zambrano, 2012).\\\\
El algoritmo SURF sigue en esencia las mismas cuatro etapas del SIFT antes mencionadas, pero para mejorar su velocidad de computación utiliza la matriz Hessiana $H(p,\sigma)$ en la primera etapa, donde $p=(x,y)$ comformada por las derivadas de segundo orden de $L$, para calcular el determinante de esta matriz se emplean aproximaciones de estas derivadas, así: $ det(H)\approx D_{xx}D_{yy}-0.9(D_{xy})^{2} $. Otra rasgo de los puntos característicos obtenidos mediante el SURF es su repetitibilidad, ya que si el keypoint resulta estable y confiable entonces será obtenido sin problema al variar la escala y la rotación, por lo que las alteraciones fotométricas y otros tipos de ruidos no suelen afectar (Romero $\&$ Cazorla, 2009).\\\\
Es importante mencionar que estos algoritmos funcionan mejor con imágenes en escala de grises, debido a esto a las imágenes a comparar se les aplicó este filtro y además en el código se indicó que el video capturado por el NAO se transmitiera en escala de grises.\\\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Desarrollo del Proyecto}
El primer punto para llevar a cabo el proyecto fue la implementación de los algoritmos descritos en la sección anterior, inicialmente la estuctura a seguir para que el programa compilara y corriera correctamente fue un obstáculo, pero se tomó un ejemplo proporcionado por aldebaran como esqueleto para el desarrollo del código. Se implementó el código del ejemplo getimage para obtener acceso a la cámara superior del NAO y así llevar a cabo la comparación con la imagen guardada en la base de datos. Mediante los algoritmos de detección de características visuales se identificó las esquinas del objeto a buscar en las imágenes vistas por el NAO, esto permitió encontrar el centro del objeto. Seguidamente se calculó el desplazamiento del centro del objeto respecto al centro del imagen y mediante el movimiento de la cabeza, girando entorno al eje Z y al eje Y, se logró que ambos centros coincidieran. Para saber cuantos radianes debía girar la cabeza el NAO según la separación se creó una escala a base de prueba y error, donde se obtuvo que al girar la cabeza en torno al eje Z cerca de 0.42 rad el centro de la imagen se desplazaba la mitad del ancho de la imagen (en calidad QVGA).\\\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metodología}
Para lo anterior fue necesario utilizar las herramientas existentes para facilitar el desarrollo del proyecto, por ejemplo, se utilizaron los API de reconocimiento de objetos y otras herramientas y algoritmos existentes. Una vez logrado el objetivo anterior, será posible trabajar con los objetos reconocidos en distintas maneras.\\\\
Todo esto se sintetizó en una librería de C++ donde se incluyeron todas las funciones anteriores y otras funciones imprevistas que se implementaron durante el desarrollo del proyecto. Finalmente, se deseó ejemplificar con un programa sencillo todo lo anterior, por ejemplo, que el NAO reconozca un objeto con bastantes características y que haga alguna acción simple después de reconocer el objeto. El código creado se puede  recrear en el simulador de ALdebaran o se puede modificar para que corra localmente en alguno de los robots NAO que este a disposición por el PRIS-Lab.\\\\
Antes de comenzar a programar, se planificó la estructura de la librería para que el trabajo fuera más eficaz, sin embargo esta estructura sufrió mdificaciones durante el desarrollo del proyecto. Una vez hecho esto, se estudió el funcionamiento de los API de reconocimiento de objetos así como algunos algoritmos que ayuden a cumplir con el desarrollo del proyecto y con los objetivos. Por ejemplo, se analizaron los ejemplos y se investigó en la teoría que proporciona el libro An introduction to robotics with NAO de Aldebaran Robotics así como la documentación disponible en línea, para comprender mejor los problemas enfrentados. También, se consultaron diferentes referencias como tesis, artículos de revistas y páginas web que contenían información escencial. Finalmente, se creó un video donde se expuso el desarrollo del trabajo, así como los resultados obtenidos y sus implicaciones, así como una muestra del programa en acción.\\\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusiones}
En este proyecto se logró expandir las funciones de detección de objetos del robot NAO, haciendo posible el reconocimiento casi de cualquier elemento con solo ser agregado previamente a una base de datos, con excepción de algunos que sean tan simples que no tengan casi irregularidades o características para realizar la comparación.\\\\ 
	
En cuanto a las limitaciones que se presentaron, una es que al ejecutar el programa de forma remota, la transmisión de datos es muy lenta ya que es limitada por la velocidad del Wi-Fi, se disminuyó la calidad de la imagen lo posible, pero aun así la velocidad de transmisión fue muy lenta y por lo tanto su ejecución no es tan eficiente.  Esto se podría evitar mediante una compilación cruzada utilizando la herramienta Nao Atom Cross Tool Chain proporcionada por el fabricante, y de esta forma ejecutar el programa internamente en el sistema operativo del robot, consiguiendo un mejor desempeño.\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Anexos}
\subsection{main.cpp}
\lstinputlisting{main.cpp}
\subsection{naocam.h}
\lstinputlisting{naocam.h}
\subsection{naocam.cpp}
\lstinputlisting{naocam.cpp}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Referencias}

\begin{enumerate}
\item Aldebaran (2014). \textit{NAO Robot: intelligent and friendly companion}.Recuperado de $ http://www.aldebaran.com/en/humanoid\-robot/nao\-robot $
\item Aldebaran (2014). \textit{NAO Documentation}.Recuperado de $ http://doc.aldebaran.com/1-14/ $
\item Aracil, R. (2012). \textit{Desarrollo de un sistema cognitivo de visión para la navegación robótica}. Tesis de licenciatura no publicada, Universidad Polit\`{e}ctica de Val\`{e}ncia, Valencia, España.
\item Beiter, M., Coltin B., Liemhetcharat, S., \textit{An Introduction To Robotics With NAO}, Aldebaran Robotics, 2012.
\item Plaza, A. \& J. Zambrano. \textit{Estudio y Selección de las Técnicas SIFT, SURF y ASIFT de Reconocimiento de Imágenes para el Diseño de un Prototipo en Dispositivos Móviles}. Tesis de licenciatura no publicada, Universidad Politéctica Salesiana, Cuenca, Ecuador.
\item Romero, A. \& M. Cazorla. \textit{Comparativa de detectores de características visuales y su aplicación al SLAM}. Actas del X Workshop de Agentes Físicos. Cáceres, España. pp. 55-62.
\item Solano, A. (2014). \textit{Desarrollo de funciones de movimiento y control de los sensores para una plataforma robótica NAO}. Tesis de licenciatura no publicada, Universidad de Costa Rica, Ciudad Universitaria "Rodrigo Facio", Costa Rica.

\end{enumerate}
	
\end{document}

